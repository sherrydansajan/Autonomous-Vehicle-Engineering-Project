# -*- coding: utf-8 -*-
"""Decision treeTiltPrediction_XGBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bZsgBNyFlK0_TNPGezP-9XQ1v54lJT1b
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense

# Load data from the CSV file
#df = pd.read_csv('auto_tiltdataset.csv')
df = pd.read_csv('dataset_carla.csv')

# Preprocess the data (e.g., handle missing values, scale features, etc.)
# Example:
df.dropna(inplace=True)  # Drop rows with missing values
X = df.drop('Theta', axis=1)  # Features
y = df['Theta']  # Target variable
df.head()

import seaborn as sns
import matplotlib.pyplot as plt

temp = df.head(4000)
features = list(temp.columns)[:-1]
# Create subplots
fig, axes = plt.subplots(nrows=len(features), ncols=1, figsize=(8, 6 * len(features)))

# Plot each numerical column against the label
for i, column in enumerate(features):
    sns.scatterplot(x=temp[column], y=temp['Theta'], ax=axes[i])
    axes[i].set_xlabel(column)
    axes[i].set_ylabel('Theta')

plt.tight_layout()
plt.show()

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import GridSearchCV

model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=4)
model.fit(X_train, y_train)

# Make predictions on the test set
predictions = model.predict(X_test)

# Calculate mean squared error
mse = mean_squared_error(y_test, predictions)
print("Mean Squared Error:", mse)

mae = mean_absolute_error(y_test, predictions)
print("Mean Absolute Error:", mae)

# Calculate R-squared (R^2)
r2 = r2_score(y_test, predictions)
print("R-squared (R^2):", r2)

import pickle

# Save the trained model to a file
with open('xgboost_model.pkl', 'wb') as file:
    pickle.dump(model, file)

# Load the model from the file
import pickle
#import pandas as pd
#from sklearn.model_selection import train_test_split


with open('xgboost_model.pkl', 'rb') as file:
    loaded_model = pickle.load(file)

# Make predictions using the loaded model
predictions_loaded_model = loaded_model.predict(X_test)

predictions_loaded_model

X_test

# Let's say you want to predict theta for mass=100 kg, radius_of_curvature=10 m, and additional features
mass = 51.6  # kg
radius_of_curvature = 2  # m
cof=0.8
speed=0.348
import numpy as np
f_seat = mass*9.8
f_friction = f_seat*cof

formula_theta = np.arctan(f_seat*(speed**2) - f_friction*9.8*radius_of_curvature/(f_seat+f_friction*speed**2))

dummy_data = {
    'Speed_car': [speed],
    'cof_Range': [cof],
    'Radius_curvature': [radius_of_curvature],
    'Mass_person': [mass]
}

# Create a DataFrame from the dictionary
dummy_df = pd.DataFrame(dummy_data)

prediction = np.abs(loaded_model.predict(dummy_df))
prediction

formula_theta

from sklearn.metrics import mean_squared_error
# Extract the 'Theta' values from the ground truth DataFrame
y_true = formula_theta

# Extract the predicted 'Theta' values from the prediction output DataFrame
y_pred = prediction[0]

# Calculate mean absolute error
error = round(np.abs(y_true - y_pred),2)
percent_error = round(error*100/formula_theta,2)

print(f'Predicted theta: {y_pred}')
print(f'Formula theta: {formula_theta}')
print(f'Absolute error: {error}')
print(f'Percent error = {percent_error}%')



from ipywidgets import interact, widgets

def predict_and_calculate_error(mass_value,cof_value):
    # Update the mass value in the dummy DataFrame
    dummy_df['Mass_person'] = mass_value
    dummy_df['cof_Range'] = cof_value

    # Make predictions with your XGBoost model

    # Extract the 'Theta' values from the ground truth DataFrame
    f_seat = mass_value*9.8
    f_friction = f_seat*cof_value
    formula_theta_var = np.arctan(f_seat*(speed**2) - f_friction*9.8*radius_of_curvature/(f_seat+f_friction*speed**2))
    y_true = formula_theta_var

    # Extract the predicted 'Theta' values from the prediction output DataFrame
    prediction_var = np.abs(loaded_model.predict(dummy_df))
    y_pred_var = prediction_var[0]

    # Calculate mean squared error
    #mse = mean_squared_error(y_true, y_pred)
    error = round(np.abs(y_true - y_pred_var),2)

    # Print the mean squared error
    print("Mass Value:", mass_value)
    print(f'Predicted theta: {y_pred_var}')
    print(f'Formula theta: {formula_theta_var}')
    print("Error:", error)

mass_slider = widgets.FloatSlider(value=70, min=50, max=120, step=0.01, description='Mass Value')
cof_slider = widgets.FloatSlider(value=0.9, min=0.6, max=1, step=0.01, description='Friction coeff.')

# Define an interactive widget
interactive_plot = interact(predict_and_calculate_error, mass_value=mass_slider, cof_value = cof_slider)